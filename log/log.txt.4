INFO Thread-3 org.apache.spark.SparkContext - Running Spark version 3.1.2
INFO Thread-3 org.apache.spark.resource.ResourceUtils - ==============================================================
INFO Thread-3 org.apache.spark.resource.ResourceUtils - No custom resources configured for spark.driver.
INFO Thread-3 org.apache.spark.resource.ResourceUtils - ==============================================================
INFO Thread-3 org.apache.spark.SparkContext - Submitted application: pyspark-shell
INFO Thread-3 org.apache.spark.resource.ResourceProfile - Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
INFO Thread-3 org.apache.spark.resource.ResourceProfile - Limiting resource is cpu
INFO Thread-3 org.apache.spark.resource.ResourceProfileManager - Added ResourceProfile id: 0
INFO Thread-3 org.apache.spark.SecurityManager - Changing view acls to: zafer
INFO Thread-3 org.apache.spark.SecurityManager - Changing modify acls to: zafer
INFO Thread-3 org.apache.spark.SecurityManager - Changing view acls groups to: 
INFO Thread-3 org.apache.spark.SecurityManager - Changing modify acls groups to: 
INFO Thread-3 org.apache.spark.SecurityManager - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(zafer); groups with view permissions: Set(); users  with modify permissions: Set(zafer); groups with modify permissions: Set()
INFO Thread-3 org.apache.spark.util.Utils - Successfully started service 'sparkDriver' on port 58083.
INFO Thread-3 org.apache.spark.SparkEnv - Registering MapOutputTracker
INFO Thread-3 org.apache.spark.SparkEnv - Registering BlockManagerMaster
INFO Thread-3 org.apache.spark.storage.BlockManagerMasterEndpoint - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
INFO Thread-3 org.apache.spark.storage.BlockManagerMasterEndpoint - BlockManagerMasterEndpoint up
INFO Thread-3 org.apache.spark.SparkEnv - Registering BlockManagerMasterHeartbeat
INFO Thread-3 org.apache.spark.storage.DiskBlockManager - Created local directory at C:\Users\zafer\AppData\Local\Temp\blockmgr-2fbc1197-c9bf-40e8-9c04-a34e76c94308
INFO Thread-3 org.apache.spark.storage.memory.MemoryStore - MemoryStore started with capacity 366.3 MiB
INFO Thread-3 org.apache.spark.SparkEnv - Registering OutputCommitCoordinator
INFO Thread-3 org.apache.spark.util.Utils - Successfully started service 'SparkUI' on port 4040.
INFO Thread-3 org.apache.spark.ui.SparkUI - Bound SparkUI to 0.0.0.0, and started at http://192.168.2.48:4040
INFO Thread-3 org.apache.spark.executor.Executor - Starting executor ID driver on host 192.168.2.48
INFO Thread-3 org.apache.spark.util.Utils - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 58106.
INFO Thread-3 org.apache.spark.network.netty.NettyBlockTransferService - Server created on 192.168.2.48:58106
INFO Thread-3 org.apache.spark.storage.BlockManager - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
INFO Thread-3 org.apache.spark.storage.BlockManagerMaster - Registering BlockManager BlockManagerId(driver, 192.168.2.48, 58106, None)
INFO dispatcher-BlockManagerMaster org.apache.spark.storage.BlockManagerMasterEndpoint - Registering block manager 192.168.2.48:58106 with 366.3 MiB RAM, BlockManagerId(driver, 192.168.2.48, 58106, None)
INFO Thread-3 org.apache.spark.storage.BlockManagerMaster - Registered BlockManager BlockManagerId(driver, 192.168.2.48, 58106, None)
INFO Thread-3 org.apache.spark.storage.BlockManager - Initialized BlockManager: BlockManagerId(driver, 192.168.2.48, 58106, None)
INFO Thread-3 org.apache.spark.sql.internal.SharedState - Setting hive.metastore.warehouse.dir ('null') to the value of spark.sql.warehouse.dir ('file:/C:/Users/zafer/Desktop/abn_amro/proje/spark-warehouse').
INFO Thread-3 org.apache.spark.sql.internal.SharedState - Warehouse path is 'file:/C:/Users/zafer/Desktop/abn_amro/proje/spark-warehouse'.
INFO Thread-3 org.apache.spark.sql.execution.datasources.InMemoryFileIndex - It took 40 ms to list leaf files for 1 paths.
INFO Thread-3 org.apache.spark.sql.execution.datasources.InMemoryFileIndex - It took 4 ms to list leaf files for 1 paths.
INFO Thread-3 org.apache.spark.sql.execution.datasources.FileSourceStrategy - Pushed Filters: 
INFO Thread-3 org.apache.spark.sql.execution.datasources.FileSourceStrategy - Post-Scan Filters: (length(trim(value#0, None)) > 0)
INFO Thread-3 org.apache.spark.sql.execution.datasources.FileSourceStrategy - Output Data Schema: struct<value: string>
INFO Thread-3 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 411.6429 ms
INFO Thread-3 org.apache.spark.storage.memory.MemoryStore - Block broadcast_0 stored as values in memory (estimated size 303.4 KiB, free 366.0 MiB)
INFO Thread-3 org.apache.spark.storage.memory.MemoryStore - Block broadcast_0_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 366.0 MiB)
INFO dispatcher-BlockManagerMaster org.apache.spark.storage.BlockManagerInfo - Added broadcast_0_piece0 in memory on 192.168.2.48:58106 (size: 27.6 KiB, free: 366.3 MiB)
INFO Thread-3 org.apache.spark.SparkContext - Created broadcast 0 from csv at <unknown>:0
INFO Thread-3 org.apache.spark.sql.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
INFO Thread-3 org.apache.spark.SparkContext - Starting job: csv at <unknown>:0
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 0 (csv at <unknown>:0) with 1 output partitions
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 0 (csv at <unknown>:0)
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 0 (MapPartitionsRDD[3] at csv at <unknown>:0), which has no missing parents
INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_1 stored as values in memory (estimated size 10.8 KiB, free 366.0 MiB)
INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_1_piece0 stored as bytes in memory (estimated size 5.4 KiB, free 366.0 MiB)
INFO dispatcher-BlockManagerMaster org.apache.spark.storage.BlockManagerInfo - Added broadcast_1_piece0 in memory on 192.168.2.48:58106 (size: 5.4 KiB, free: 366.3 MiB)
INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 1 from broadcast at DAGScheduler.scala:1388
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 0 (MapPartitionsRDD[3] at csv at <unknown>:0) (first 15 tasks are for partitions Vector(0))
INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 0.0 with 1 tasks resource profile 0
INFO dispatcher-event-loop-2 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 0.0 (TID 0) (192.168.2.48, executor driver, partition 0, PROCESS_LOCAL, 4886 bytes) taskResourceAssignments Map()
INFO Executor task launch worker for task 0.0 in stage 0.0 (TID 0) org.apache.spark.executor.Executor - Running task 0.0 in stage 0.0 (TID 0)
INFO Executor task launch worker for task 0.0 in stage 0.0 (TID 0) org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///C:/Users/zafer/Desktop/abn_amro/proje/dataset_one.csv, range: 0-52041, partition values: [empty row]
INFO Executor task launch worker for task 0.0 in stage 0.0 (TID 0) org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 20.2349 ms
INFO Executor task launch worker for task 0.0 in stage 0.0 (TID 0) org.apache.spark.executor.Executor - Finished task 0.0 in stage 0.0 (TID 0). 1595 bytes result sent to driver
INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 0.0 (TID 0) in 626 ms on 192.168.2.48 (executor driver) (1/1)
INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 0.0, whose tasks have all completed, from pool 
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 0 (csv at <unknown>:0) finished in 0,788 s
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 0: Stage finished
INFO Thread-3 org.apache.spark.scheduler.DAGScheduler - Job 0 finished: csv at <unknown>:0, took 0,849342 s
INFO Thread-3 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 16.8024 ms
INFO Thread-3 org.apache.spark.sql.execution.datasources.FileSourceStrategy - Pushed Filters: 
INFO Thread-3 org.apache.spark.sql.execution.datasources.FileSourceStrategy - Post-Scan Filters: 
INFO Thread-3 org.apache.spark.sql.execution.datasources.FileSourceStrategy - Output Data Schema: struct<value: string>
INFO Thread-3 org.apache.spark.storage.memory.MemoryStore - Block broadcast_2 stored as values in memory (estimated size 303.4 KiB, free 365.7 MiB)
INFO Thread-3 org.apache.spark.storage.memory.MemoryStore - Block broadcast_2_piece0 stored as bytes in memory (estimated size 27.6 KiB, free 365.6 MiB)
INFO dispatcher-BlockManagerMaster org.apache.spark.storage.BlockManagerInfo - Added broadcast_2_piece0 in memory on 192.168.2.48:58106 (size: 27.6 KiB, free: 366.2 MiB)
INFO Thread-3 org.apache.spark.SparkContext - Created broadcast 2 from csv at <unknown>:0
INFO Thread-3 org.apache.spark.sql.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
