INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 4 (count at <unknown>:0) finished in 0,063 s
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - running: Set()
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 5)
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - failed: Set()
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[33] at count at <unknown>:0), which has no missing parents
INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 10.1 KiB, free 364.3 MiB)
INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 364.3 MiB)
INFO dispatcher-BlockManagerMaster org.apache.spark.storage.BlockManagerInfo - Added broadcast_11_piece0 in memory on 192.168.2.48:49745 (size: 5.0 KiB, free: 366.1 MiB)
INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 11 from broadcast at DAGScheduler.scala:1388
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[33] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (192.168.2.48, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
INFO Executor task launch worker for task 0.0 in stage 5.0 (TID 5) org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
INFO Executor task launch worker for task 0.0 in stage 5.0 (TID 5) org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
INFO Executor task launch worker for task 0.0 in stage 5.0 (TID 5) org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
INFO Executor task launch worker for task 0.0 in stage 5.0 (TID 5) org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 2562 bytes result sent to driver
INFO task-result-getter-1 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 15 ms on 192.168.2.48 (executor driver) (1/1)
INFO task-result-getter-1 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 5 (count at <unknown>:0) finished in 0,068 s
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 5: Stage finished
INFO Thread-3 org.apache.spark.scheduler.DAGScheduler - Job 3 finished: count at <unknown>:0, took 0,130375 s
INFO dispatcher-BlockManagerMaster org.apache.spark.storage.BlockManagerInfo - Removed broadcast_5_piece0 on 192.168.2.48:49745 in memory (size: 27.6 KiB, free: 366.1 MiB)
INFO dispatcher-BlockManagerMaster org.apache.spark.storage.BlockManagerInfo - Removed broadcast_4_piece0 on 192.168.2.48:49745 in memory (size: 5.4 KiB, free: 366.1 MiB)
INFO dispatcher-BlockManagerMaster org.apache.spark.storage.BlockManagerInfo - Removed broadcast_8_piece0 on 192.168.2.48:49745 in memory (size: 5.0 KiB, free: 366.1 MiB)
INFO dispatcher-BlockManagerMaster org.apache.spark.storage.BlockManagerInfo - Removed broadcast_3_piece0 on 192.168.2.48:49745 in memory (size: 27.6 KiB, free: 366.2 MiB)
INFO dispatcher-BlockManagerMaster org.apache.spark.storage.BlockManagerInfo - Removed broadcast_7_piece0 on 192.168.2.48:49745 in memory (size: 7.8 KiB, free: 366.2 MiB)
INFO dispatcher-BlockManagerMaster org.apache.spark.storage.BlockManagerInfo - Removed broadcast_6_piece0 on 192.168.2.48:49745 in memory (size: 27.5 KiB, free: 366.2 MiB)
INFO Thread-3 org.apache.spark.sql.catalyst.expressions.codegen.CodeGenerator - Code generated in 13.2378 ms
INFO Thread-3 org.apache.spark.SparkContext - Starting job: collect at c:\users\zafer\appdata\local\programs\python\python39\lib\site-packages\chispa\dataframe_comparer.py:68
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 4 (collect at c:\users\zafer\appdata\local\programs\python\python39\lib\site-packages\chispa\dataframe_comparer.py:68) with 4 output partitions
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 6 (collect at c:\users\zafer\appdata\local\programs\python\python39\lib\site-packages\chispa\dataframe_comparer.py:68)
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List()
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List()
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 6 (MapPartitionsRDD[45] at collect at c:\users\zafer\appdata\local\programs\python\python39\lib\site-packages\chispa\dataframe_comparer.py:68), which has no missing parents
INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_12 stored as values in memory (estimated size 11.3 KiB, free 365.3 MiB)
INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_12_piece0 stored as bytes in memory (estimated size 5.9 KiB, free 365.3 MiB)
INFO dispatcher-BlockManagerMaster org.apache.spark.storage.BlockManagerInfo - Added broadcast_12_piece0 in memory on 192.168.2.48:49745 (size: 5.9 KiB, free: 366.2 MiB)
INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 12 from broadcast at DAGScheduler.scala:1388
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 4 missing tasks from ResultStage 6 (MapPartitionsRDD[45] at collect at c:\users\zafer\appdata\local\programs\python\python39\lib\site-packages\chispa\dataframe_comparer.py:68) (first 15 tasks are for partitions Vector(0, 1, 2, 3))
INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 6.0 with 4 tasks resource profile 0
INFO dispatcher-event-loop-0 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 6.0 (TID 6) (192.168.2.48, executor driver, partition 0, PROCESS_LOCAL, 4461 bytes) taskResourceAssignments Map()
INFO dispatcher-event-loop-0 org.apache.spark.scheduler.TaskSetManager - Starting task 1.0 in stage 6.0 (TID 7) (192.168.2.48, executor driver, partition 1, PROCESS_LOCAL, 4502 bytes) taskResourceAssignments Map()
INFO dispatcher-event-loop-0 org.apache.spark.scheduler.TaskSetManager - Starting task 2.0 in stage 6.0 (TID 8) (192.168.2.48, executor driver, partition 2, PROCESS_LOCAL, 4505 bytes) taskResourceAssignments Map()
INFO dispatcher-event-loop-0 org.apache.spark.scheduler.TaskSetManager - Starting task 3.0 in stage 6.0 (TID 9) (192.168.2.48, executor driver, partition 3, PROCESS_LOCAL, 4497 bytes) taskResourceAssignments Map()
INFO Executor task launch worker for task 0.0 in stage 6.0 (TID 6) org.apache.spark.executor.Executor - Running task 0.0 in stage 6.0 (TID 6)
INFO Executor task launch worker for task 1.0 in stage 6.0 (TID 7) org.apache.spark.executor.Executor - Running task 1.0 in stage 6.0 (TID 7)
INFO Executor task launch worker for task 2.0 in stage 6.0 (TID 8) org.apache.spark.executor.Executor - Running task 2.0 in stage 6.0 (TID 8)
INFO Executor task launch worker for task 3.0 in stage 6.0 (TID 9) org.apache.spark.executor.Executor - Running task 3.0 in stage 6.0 (TID 9)
INFO Executor task launch worker for task 1.0 in stage 6.0 (TID 7) org.apache.spark.api.python.PythonRunner - Times: total = 643, boot = 627, init = 16, finish = 0
WARN executor-heartbeater org.apache.spark.executor.ProcfsMetricsGetter - Exception when trying to compute pagesize, as a result reporting of ProcessTree metrics is stopped
INFO Executor task launch worker for task 0.0 in stage 6.0 (TID 6) org.apache.spark.api.python.PythonRunner - Times: total = 1451, boot = 1451, init = 0, finish = 0
INFO Executor task launch worker for task 3.0 in stage 6.0 (TID 9) org.apache.spark.api.python.PythonRunner - Times: total = 2013, boot = 2013, init = 0, finish = 0
INFO Executor task launch worker for task 3.0 in stage 6.0 (TID 9) org.apache.spark.executor.Executor - Finished task 3.0 in stage 6.0 (TID 9). 1796 bytes result sent to driver
INFO Executor task launch worker for task 0.0 in stage 6.0 (TID 6) org.apache.spark.executor.Executor - Finished task 0.0 in stage 6.0 (TID 6). 1882 bytes result sent to driver
INFO Executor task launch worker for task 1.0 in stage 6.0 (TID 7) org.apache.spark.executor.Executor - Finished task 1.0 in stage 6.0 (TID 7). 1873 bytes result sent to driver
INFO task-result-getter-2 org.apache.spark.scheduler.TaskSetManager - Finished task 3.0 in stage 6.0 (TID 9) in 2650 ms on 192.168.2.48 (executor driver) (1/4)
INFO task-result-getter-3 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 6.0 (TID 6) in 2666 ms on 192.168.2.48 (executor driver) (2/4)
INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 1.0 in stage 6.0 (TID 7) in 2650 ms on 192.168.2.48 (executor driver) (3/4)
INFO dag-scheduler-event-loop org.apache.spark.api.python.PythonAccumulatorV2 - Connected to AccumulatorServer at host: 127.0.0.1 port: 49746
INFO Executor task launch worker for task 2.0 in stage 6.0 (TID 8) org.apache.spark.api.python.PythonRunner - Times: total = 2591, boot = 2591, init = 0, finish = 0
