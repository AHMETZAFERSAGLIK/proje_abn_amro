INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - running: Set()
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 3)
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - failed: Set()
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 3 (MapPartitionsRDD[26] at count at <unknown>:0), which has no missing parents
INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_8 stored as values in memory (estimated size 10.1 KiB, free 364.6 MiB)
INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_8_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 364.6 MiB)
INFO dispatcher-BlockManagerMaster org.apache.spark.storage.BlockManagerInfo - Added broadcast_8_piece0 in memory on 192.168.2.48:58106 (size: 5.0 KiB, free: 366.1 MiB)
INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 8 from broadcast at DAGScheduler.scala:1388
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 3 (MapPartitionsRDD[26] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 3.0 with 1 tasks resource profile 0
INFO dispatcher-event-loop-3 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 3.0 (TID 3) (192.168.2.48, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
INFO Executor task launch worker for task 0.0 in stage 3.0 (TID 3) org.apache.spark.executor.Executor - Running task 0.0 in stage 3.0 (TID 3)
INFO Executor task launch worker for task 0.0 in stage 3.0 (TID 3) org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
INFO Executor task launch worker for task 0.0 in stage 3.0 (TID 3) org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 8 ms
INFO Executor task launch worker for task 0.0 in stage 3.0 (TID 3) org.apache.spark.executor.Executor - Finished task 0.0 in stage 3.0 (TID 3). 2605 bytes result sent to driver
INFO task-result-getter-3 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 3.0 (TID 3) in 63 ms on 192.168.2.48 (executor driver) (1/1)
INFO task-result-getter-3 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 3.0, whose tasks have all completed, from pool 
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 3 (count at <unknown>:0) finished in 0,076 s
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Job 2 is finished. Cancelling potential speculative or zombie tasks for this job
INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Killing all running tasks in stage 3: Stage finished
INFO Thread-3 org.apache.spark.scheduler.DAGScheduler - Job 2 finished: count at <unknown>:0, took 0,270646 s
INFO Thread-3 org.apache.spark.sql.execution.datasources.FileSourceStrategy - Pushed Filters: 
INFO Thread-3 org.apache.spark.sql.execution.datasources.FileSourceStrategy - Post-Scan Filters: 
INFO Thread-3 org.apache.spark.sql.execution.datasources.FileSourceStrategy - Output Data Schema: struct<>
INFO Thread-3 org.apache.spark.storage.memory.MemoryStore - Block broadcast_9 stored as values in memory (estimated size 303.2 KiB, free 364.3 MiB)
INFO Thread-3 org.apache.spark.storage.memory.MemoryStore - Block broadcast_9_piece0 stored as bytes in memory (estimated size 27.5 KiB, free 364.3 MiB)
INFO dispatcher-BlockManagerMaster org.apache.spark.storage.BlockManagerInfo - Added broadcast_9_piece0 in memory on 192.168.2.48:58106 (size: 27.5 KiB, free: 366.1 MiB)
INFO Thread-3 org.apache.spark.SparkContext - Created broadcast 9 from count at <unknown>:0
INFO Thread-3 org.apache.spark.sql.execution.FileSourceScanExec - Planning scan with bin packing, max size: 4194304 bytes, open cost is considered as scanning 4194304 bytes.
INFO Thread-3 org.apache.spark.SparkContext - Starting job: count at <unknown>:0
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Registering RDD 30 (count at <unknown>:0) as input to shuffle 1
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Got job 3 (count at <unknown>:0) with 1 output partitions
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Final stage: ResultStage 5 (count at <unknown>:0)
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Parents of final stage: List(ShuffleMapStage 4)
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Missing parents: List(ShuffleMapStage 4)
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ShuffleMapStage 4 (MapPartitionsRDD[30] at count at <unknown>:0), which has no missing parents
INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_10 stored as values in memory (estimated size 15.2 KiB, free 364.3 MiB)
INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_10_piece0 stored as bytes in memory (estimated size 7.8 KiB, free 364.3 MiB)
INFO dispatcher-BlockManagerMaster org.apache.spark.storage.BlockManagerInfo - Added broadcast_10_piece0 in memory on 192.168.2.48:58106 (size: 7.8 KiB, free: 366.1 MiB)
INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 10 from broadcast at DAGScheduler.scala:1388
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ShuffleMapStage 4 (MapPartitionsRDD[30] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 4.0 with 1 tasks resource profile 0
INFO dispatcher-event-loop-2 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 4.0 (TID 4) (192.168.2.48, executor driver, partition 0, PROCESS_LOCAL, 4875 bytes) taskResourceAssignments Map()
INFO Executor task launch worker for task 0.0 in stage 4.0 (TID 4) org.apache.spark.executor.Executor - Running task 0.0 in stage 4.0 (TID 4)
INFO Executor task launch worker for task 0.0 in stage 4.0 (TID 4) org.apache.spark.sql.execution.datasources.FileScanRDD - Reading File path: file:///C:/Users/zafer/Desktop/abn_amro/proje/dataset_two.csv, range: 0-64985, partition values: [empty row]
INFO Executor task launch worker for task 0.0 in stage 4.0 (TID 4) org.apache.spark.executor.Executor - Finished task 0.0 in stage 4.0 (TID 4). 1879 bytes result sent to driver
INFO task-result-getter-0 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 4.0 (TID 4) in 33 ms on 192.168.2.48 (executor driver) (1/1)
INFO task-result-getter-0 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 4.0, whose tasks have all completed, from pool 
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ShuffleMapStage 4 (count at <unknown>:0) finished in 0,044 s
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - looking for newly runnable stages
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - running: Set()
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - waiting: Set(ResultStage 5)
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - failed: Set()
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting ResultStage 5 (MapPartitionsRDD[33] at count at <unknown>:0), which has no missing parents
INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_11 stored as values in memory (estimated size 10.1 KiB, free 364.3 MiB)
INFO dag-scheduler-event-loop org.apache.spark.storage.memory.MemoryStore - Block broadcast_11_piece0 stored as bytes in memory (estimated size 5.0 KiB, free 364.3 MiB)
INFO dispatcher-BlockManagerMaster org.apache.spark.storage.BlockManagerInfo - Added broadcast_11_piece0 in memory on 192.168.2.48:58106 (size: 5.0 KiB, free: 366.1 MiB)
INFO dag-scheduler-event-loop org.apache.spark.SparkContext - Created broadcast 11 from broadcast at DAGScheduler.scala:1388
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Submitting 1 missing tasks from ResultStage 5 (MapPartitionsRDD[33] at count at <unknown>:0) (first 15 tasks are for partitions Vector(0))
INFO dag-scheduler-event-loop org.apache.spark.scheduler.TaskSchedulerImpl - Adding task set 5.0 with 1 tasks resource profile 0
INFO dispatcher-event-loop-1 org.apache.spark.scheduler.TaskSetManager - Starting task 0.0 in stage 5.0 (TID 5) (192.168.2.48, executor driver, partition 0, NODE_LOCAL, 4453 bytes) taskResourceAssignments Map()
INFO Executor task launch worker for task 0.0 in stage 5.0 (TID 5) org.apache.spark.executor.Executor - Running task 0.0 in stage 5.0 (TID 5)
INFO Executor task launch worker for task 0.0 in stage 5.0 (TID 5) org.apache.spark.storage.ShuffleBlockFetcherIterator - Getting 1 (60.0 B) non-empty blocks including 1 (60.0 B) local and 0 (0.0 B) host-local and 0 (0.0 B) remote blocks
INFO Executor task launch worker for task 0.0 in stage 5.0 (TID 5) org.apache.spark.storage.ShuffleBlockFetcherIterator - Started 0 remote fetches in 0 ms
INFO Executor task launch worker for task 0.0 in stage 5.0 (TID 5) org.apache.spark.executor.Executor - Finished task 0.0 in stage 5.0 (TID 5). 2605 bytes result sent to driver
INFO task-result-getter-1 org.apache.spark.scheduler.TaskSetManager - Finished task 0.0 in stage 5.0 (TID 5) in 32 ms on 192.168.2.48 (executor driver) (1/1)
INFO task-result-getter-1 org.apache.spark.scheduler.TaskSchedulerImpl - Removed TaskSet 5.0, whose tasks have all completed, from pool 
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - ResultStage 5 (count at <unknown>:0) finished in 0,042 s
INFO dag-scheduler-event-loop org.apache.spark.scheduler.DAGScheduler - Job 3 is finished. Cancelling potential speculative or zombie tasks for this job
